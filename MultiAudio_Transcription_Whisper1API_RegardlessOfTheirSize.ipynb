{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf00849b-b54d-43a5-ae79-fc77c8835f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "# hide sensible OpenAI key information by importing environment variables from an env. file\n",
    "load_dotenv(r\"OpenAI.env\")\n",
    "\n",
    "# store your API key in a variable            \n",
    "OPENAI_API_KEY= os.environ.get(\"name of your api key in the env file\")\n",
    "client=OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f355ee4b-139c-4748-908c-391ec3c95ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(file_path, target_size_mb=10, format='mp3'):\n",
    "    # Load the file using AudioSegment from pydub\n",
    "    audio = AudioSegment.from_file(file_path, format=format)\n",
    "\n",
    "    # estimate the maximum duration of each segment i miliseconds base on the target size in MB\n",
    "    # Use a conversative estimate of bitrate  (128 kps) for mp3 to calculate duration\n",
    "    # 1 Byte = 128 kps, so 128000 bits per second = 1600 Bytes\n",
    "    estimated_bitrate = 128000  # in bps\n",
    "    bytes_per_second = estimated_bitrate / 8\n",
    "    \n",
    "    # we want to split segments into a maximum size of 10 MB because using 20 or 24 MB always led to API disconnects\n",
    "    max_segment_duration_ms = int((target_size_mb * 1024 * 1024 / bytes_per_second) * 1000)\n",
    "\n",
    "    # create a list to store the names of the chunks\n",
    "    chunks = []\n",
    "    \n",
    "    # using a for loop to split big audio files into chunks and save them as separate chunked files with the index name\n",
    "    for i in range(0, len(audio), max_segment_duration_ms):\n",
    "        chunk = audio[i:i+max_segment_duration_ms]\n",
    "        chunk_name = f\"{file_path}_part{i//max_segment_duration_ms}.{format}\"\n",
    "        chunk.export(chunk_name, format=format)\n",
    "        chunks.append(chunk_name)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# using the Whisper API client to transcribe audio files\n",
    "def transcribe_audio(file_path):\n",
    "    # open audio files in read-binary mode because audio files are binary data \n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        # send audio file to the whisper  transcription service using the api client and return transcription (response.text)\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# create a directory where we want to store the transcriptions if it doesn't exist yet\n",
    "def process_directory(directory_path):\n",
    "    # this will create a subfolder /transcriptions inside the folder where the audio files are located (if it doesn't exist yet)\n",
    "    output_dir = os.path.join(directory_path, \"transcriptions\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # iterate over all mp3 files in the audio file directory\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.mp3'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            # initialize an empty string that we'll use for batch transcribing files larger than 10 MB\n",
    "            complete_transcription=\"\"\n",
    "\n",
    "            # here comes the tricky part: if a mp3 file is bigger than 10 MB\n",
    "            # we use the split audio function to  split the audio into chunks, each 10 MB or less\n",
    "            if file_size > 10 * 1024 * 1024:\n",
    "                parts = split_audio(file_path)\n",
    "\n",
    "                # for each chunk, we want to batch transcribe that chunk and add the transcription text to the empty string from before\n",
    "                for part in parts:\n",
    "                    part_transcription=transcribe_audio(part)\n",
    "                    complete_transcription += part_transcription + \" \"\n",
    "                    # after the part has been transcribed, we want to remove the chunked file from our directory so we don't end with a lot of chunked files\n",
    "                    os.remove(part)\n",
    "            \n",
    "            # if the mp3 file is NOT bigger than 10 MB, we want to transcribe it directly without any chunking\n",
    "            else:\n",
    "                complete_transcription = transcribe_audio(file_path)\n",
    "\n",
    "            # after transcription, write the complete transcription to our output directory with the same name as the audio file as a text file\n",
    "            transcription_file_path = os.path.join(output_dir, file_name.replace('.mp3', '.txt'))\n",
    "            with open(transcription_file_path, 'w') as f:\n",
    "                f.write(complete_transcription)\n",
    "\n",
    "\n",
    "# define your local directory that contains all the audio files by copy & pasting the directory path below\n",
    "directory_path = \"your directory path here\"\n",
    "\n",
    "# call the process_directory to start the directory transcription process\n",
    "process_directory(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
